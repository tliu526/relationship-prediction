{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic location feature extraction\n",
    "\n",
    "This notebook extracts communication features in the context of semantic locations. Some processing functions pulled from Sohrab's [data analysis repository](https://github.com/sosata/CS120DataAnalysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "from df_utils import *\n",
    "from sys import exit\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../CS120/CS120-sensor-csvs/1114936/eml.csv\n",
      "[\n",
      "[['1446824670.327', 'd972b551eeb588d9700db3f725580455', 'd972b551eeb588d9700db3f725580455', 'PHONE', 'OUTGOING']]\n"
     ]
    }
   ],
   "source": [
    "#probes = ['act','app','aud','bat','cal','coe','fus','lgt','run','scr','tch','wif','wtr']\n",
    "\n",
    "# communication-related features\n",
    "probes = ['act', 'cal', 'coe', 'fus']\n",
    "\n",
    "data_dir = '../CS120/CS120-sensor-csvs/'\n",
    "weather_data_dir = '/data/CS120Weather/'\n",
    "out_dir = 'processed_data/'\n",
    "\n",
    "subjects = os.listdir(data_dir)\n",
    "subjects = ['1114936'] # temporary for testing\n",
    "\n",
    "for subj in subjects:\n",
    "    filename = data_dir + subj + '/eml.csv'\n",
    "    if os.path.exists(filename):\n",
    "        print(filename)\n",
    "        loc = []\n",
    "        lat_report = []\n",
    "        lng_report = []\n",
    "        t_report = []\n",
    "        with open(filename) as file_in:\n",
    "            data = csv.reader(file_in, delimiter='\\t')\n",
    "            eml = []\n",
    "            for data_row in data:\n",
    "                if data_row:\n",
    "                    # reading location category (state)\n",
    "                    loc_string = data_row[6]\n",
    "                    loc_string = loc_string[1:len(loc_string)-1]\n",
    "                    loc_string.split(',')\n",
    "                    loc.append(loc_string)\n",
    "                    \n",
    "                    # reading lat. and long.\n",
    "                    lat_report.append(float(data_row[2]))\n",
    "                    lng_report.append(float(data_row[3]))\n",
    "                    t_report.append(float(data_row[0]))\n",
    "                    \n",
    "                    # adding to eml\n",
    "                    eml.append(data_row)\n",
    "                    \n",
    "        file_in.close()\n",
    "    else:\n",
    "        print('skipping subject '+subj+' without location report/foursquare data.')\n",
    "        continue\n",
    "        \n",
    "                      \n",
    "    # looking into data between current and previous report\n",
    "    filename = data_dir + subj + '/fus.csv'\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename) as file_in:\n",
    "            data_gps = csv.reader(file_in, delimiter='\\t')\n",
    "            t_gps = []\n",
    "            lat_gps = []\n",
    "            lng_gps = []\n",
    "            for row_gps in data_gps:\n",
    "                if row_gps:\n",
    "                    t_gps.append(float(row_gps[0]))\n",
    "                    lat_gps.append(float(row_gps[1]))\n",
    "                    lng_gps.append(float(row_gps[2]))\n",
    "        file_in.close()\n",
    "    else:\n",
    "        print('skipping subject '+subj+' without location data.')\n",
    "        continue\n",
    "\n",
    "    if os.path.exists(out_dir+subj):\n",
    "       shutil.rmtree(out_dir+subj)\n",
    "       os.makedirs(out_dir+subj)\n",
    "    else:\n",
    "       os.makedirs(out_dir+subj)\n",
    "    \n",
    "    t_prev = 0\n",
    "\n",
    "\n",
    "    for (i,eml_row) in enumerate(eml):\n",
    "\n",
    "        # finding t_start and t_end from gps data\n",
    "        t_start, t_end = get_time_from_gps(data_dir+subj, t_report[i], t_prev, lat_report[i], lng_report[i])\n",
    "        print(eml_row[6][0])\n",
    "\n",
    "        # if there is any clusters found, extract sensor data and put in a separate file\n",
    "        if len(t_start)>0:\n",
    "            data = get_data_at_location(data_dir+subj, t_start, t_end, 'coe')\n",
    "            if len(data)>0:\n",
    "                print(data)\n",
    "                break\n",
    "        # continue iteration\n",
    "        if i<len(t_report)-1:\n",
    "            if t_report[i]!=t_report[i+1]:\n",
    "                t_prev = t_report[i]\n",
    "\n",
    "\n",
    "#         # creating a dir and writing the eml row \n",
    "# #         loc_dir = out_dir+subj+'/'+str(i)\n",
    "# #         if not os.path.exists(loc_dir):\n",
    "# #            os.makedirs(loc_dir)\n",
    "# #         with open(loc_dir+'/'+'eml.csv','w') as f:\n",
    "# #            fwriter = csv.writer(f, delimiter='\\t', quotechar='|',quoting=csv.QUOTE_MINIMAL)\n",
    "# #            fwriter.writerow(eml_row)\n",
    "# #         f.close()\n",
    "        \n",
    "#         # if there is any clusters found, extract sensor data and put in a separate file\n",
    "#         if len(t_start)>0:\n",
    "#             for probe in probes:\n",
    "#                 if probe=='wtr':\n",
    "#                     data = get_data_at_location(weather_data_dir+subj, t_start, t_end, probe)\n",
    "#                 else:\n",
    "#                     data = get_data_at_location(data_dir+subj, t_start, t_end, probe)\n",
    "#                 if len(data)>0:\n",
    "#                     with open(loc_dir+'/'+probe+'.csv', 'w') as f:\n",
    "#                         fwriter = csv.writer(f, delimiter='\\t', quotechar='|',quoting=csv.QUOTE_MINIMAL)\n",
    "#                         for (j,d) in enumerate(data):\n",
    "#                             fwriter.writerow(d)\n",
    "#                     f.close()\n",
    "#         else:\n",
    "#             print('instance '+str(i)+' skipped')\n",
    "\n",
    "#         if i<len(t_report)-1:\n",
    "#             if t_report[i]!=t_report[i+1]:\n",
    "#                 t_prev = t_report[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eml)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
